# import re
# def count_non_chinese_english_digits_punctuation(text):
#     # å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼ï¼ŒåŒ¹é…ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—å’Œå¸¸è§æ ‡ç‚¹ç¬¦å·
#     # \u4e00-\u9fa5 åŒ¹é…ä¸­æ–‡æ±‰å­—
#     # a-zA-Z åŒ¹é…è‹±æ–‡å­—æ¯
#     # 0-9 åŒ¹é…æ•°å­—
#     # !"#$%&\'()*+,-./:;<=>?@[\\]^_`{|}~ åŒ¹é…å¸¸è§è‹±æ–‡æ ‡ç‚¹ç¬¦å·
#     # ï¼Œã€‚ã€ï¼›ï¼šï¼Ÿï¼â€œâ€â€˜â€™ã€Šã€‹ã€ã€‘ã€”ã€•ï¼ˆï¼‰â€”â€¦Â·ï¹ï¹â”€ åŒ¹é…å¸¸è§ä¸­æ–‡æ ‡ç‚¹ç¬¦å·
#     chinese_par=u'[\u4e00-\u9fa5]'
#     english_par=u'[a-zA-Z\w\s]'
#     digit_par=u'[0-9]'
#     punctuation_par=u'[!"#$%&\'()*+,-./:;<=>?@[\\]^_`{|}~ï¼Œã€‚ã€ï¼›ï¼šï¼Ÿï¼â€œâ€â€˜â€™ã€Šã€‹ã€ã€‘ã€”ã€•ï¼ˆï¼‰â€”â€¦Â·ï¹ï¹â”€]'
#     # ä½¿ç”¨ re.sub å‡½æ•°å°†åŒ¹é…çš„å­—ç¬¦æ›¿æ¢ä¸ºç©ºå­—ç¬¦ä¸²
#     text = re.sub(chinese_par, '', text)
#     text = re.sub(english_par, '', text)
#     text = re.sub(digit_par, '', text)
#     text = re.sub(punctuation_par, '', text)
#     print(text)
#     # ç»Ÿè®¡å‰©ä½™å­—ç¬¦çš„æ•°é‡
#     return len(text)
#
# text='#èŒ¶é¢œæ‚¦è‰²[è¶…è¯]# ğŸèŒ¶é¢œè›‡å¹´ä¸Šæ–°ğŸ†•é€Ÿæ¥æ¥å¥½è¿â—ï¸ èŒ¶é¢œç»™å¤§å®¶æ‹œæ—©å¹´å•¦ğŸ§¨ å·³è›‡ğŸå‡ºæ¥æ¥ç­è¾°ğŸ² ä¹Ÿç»™å¤§å®¶å¸¦æ¥äº†è›‡å¹´ä¸»é¢˜æ–°å‘¨è¾¹ğŸ ã€ä»Šå¹´æœ‰ç¦å…®ã€‘å­—å­—çš†ç¥ç¦~ æ–°å¹´ä¸€èµ·äº¤å¥½è¿å§~~~ #èŒ¶é¢œæ‚¦è‰²##èŒ¶é¢œå®¶æ—##èŒ¶é¢œæ–°å¹´ç¤¼##èŒ¶é¢œé™€èºå¤§ç‹##é•¿æ²™åƒå–ç©ä¹##è›‡å¹´#'
# print(count_non_chinese_english_digits_punctuation(text))

import numpy as np
from sklearn.cluster import KMeans


# ç”Ÿæˆä¸€äº›ç¤ºä¾‹ä¸€ç»´æ•°æ®
data = np.array([1, 3, 5, 7, 9, 11, 13, 15, 17, 19]).reshape(-1, 1)

# è®¾ç½®ç°‡çš„æ•°é‡
k = 3

# ä½¿ç”¨K - meansç®—æ³•è¿›è¡Œèšç±»
kmeans = KMeans(n_clusters=k, random_state=0).fit(data)

# è·å–æ¯ä¸ªæ•°æ®ç‚¹æ‰€å±çš„ç°‡æ ‡ç­¾
labels = kmeans.labels_

# è·å–ç°‡ä¸­å¿ƒ
cluster_centers = kmeans.cluster_centers_

# å°†æ¯ä¸ªæ•°æ®ç‚¹æ›¿æ¢ä¸ºå…¶æ‰€å±ç°‡çš„ä¸­å¿ƒï¼Œå®ç°ç¦»æ•£åŒ–
discretized_data = np.array([cluster_centers[label] for label in labels])

print("åŸå§‹æ•°æ®:", data.flatten())
print("ç¦»æ•£åŒ–åçš„æ•°æ®:", discretized_data.flatten())
